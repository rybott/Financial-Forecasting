{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping Through different variables to find the best combination\n",
    "\n",
    "## Results\n",
    "### Starting Data - 1 month\n",
    "- Best Results\n",
    "    1. Data Order =\n",
    "    2. Underlying Data Type =\n",
    "    3. Number of Feilds =\n",
    "    4. Derivatives =\n",
    "    5. TA's =\n",
    "- Best Combination for XGBoost\n",
    "    1. Data Order =\n",
    "    2. Underlying Data Type =\n",
    "    3. Number of Feilds =\n",
    "    4. Derivatives =\n",
    "    5. TA's =\n",
    "- Best Combination for Logistic Regression\n",
    "    1. Data Order =\n",
    "    2. Underlying Data Type =\n",
    "    3. Number of Feilds =\n",
    "    4. Derivatives =\n",
    "    5. TA's = \n",
    "- Best Combination for LSTM\n",
    "    1. Data Order =\n",
    "    2. Underlying Data Type =\n",
    "    3. Number of Feilds =\n",
    "    4. Derivatives =\n",
    "    5. TA's =\n",
    "## Process\n",
    "### Get the Data\n",
    "1. Start with 1 month of data for speed\n",
    "2. Continue with 1 year of data\n",
    "3. Based on the random data vs ordered data, take 1 year of random data\n",
    "    (Look at the the whole database and pull out a number of random entries equivalent to 1 years worth)\n",
    "4. Take the most efficient process and apply it to the whole dataset in subgroups, randomly assigning groups. Steps 3 and 4 are to prevent overfitting over a single Ticker\n",
    "\n",
    "### Processing \n",
    "1. I have 7 variables to test\n",
    "    1. Number of Fields - Number of fields in the packet (lookback period)\n",
    "    2. Derivative - Using the First and Second Derivative, and using it on:\n",
    "        - Raw Data\n",
    "        - Percent Change\n",
    "        - EMA8, SMA8, EMA20, SMA20\n",
    "        - Mix of these\n",
    "    3. EMAs\n",
    "    4. SMAs\n",
    "    5. Other\n",
    "    6. Underlying Data\n",
    "    7. Data Order\n",
    "2. Loop Through all of the variables and test the XGBoost on all of them\n",
    "3. Loop Through all of them and test Logistic Regression\n",
    "4. Loop Through all of them and test LSTM Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing for LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
