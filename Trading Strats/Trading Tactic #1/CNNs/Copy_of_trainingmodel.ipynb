{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9AzBdM1sOpx"
      },
      "source": [
        "# Long Short Term memory and other Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "292ikZRUsOpy",
        "outputId": "0d458cf2-2499-4706-f7d2-ba614e7e13d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50839 entries, 0 to 50838\n",
            "Data columns (total 15 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Profit      25552 non-null  float64\n",
            " 1   EMA8_pct    50831 non-null  float64\n",
            " 2   EMA10_pct   50829 non-null  float64\n",
            " 3   EMA20_pct   50819 non-null  float64\n",
            " 4   EMA50_pct   50789 non-null  float64\n",
            " 5   EMA75_pct   50764 non-null  float64\n",
            " 6   EMA100_pct  50739 non-null  float64\n",
            " 7   SMA8_pct    50831 non-null  float64\n",
            " 8   SMA10_pct   50829 non-null  float64\n",
            " 9   SMA20_pct   50819 non-null  float64\n",
            " 10  SMA50_pct   50789 non-null  float64\n",
            " 11  SMA75_pct   50764 non-null  float64\n",
            " 12  SMA100_pct  50739 non-null  float64\n",
            " 13  dydx        50838 non-null  float64\n",
            " 14  dydx2       50097 non-null  float64\n",
            "dtypes: float64(15)\n",
            "memory usage: 5.8 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import os\n",
        "import csv\n",
        "import itertools\n",
        "\n",
        "\n",
        "def trail_stoploss(row, tradingdata, whole_percentage):\n",
        "    idx = row.name\n",
        "    td = tradingdata\n",
        "    pct = whole_percentage/100\n",
        "    max_holdtime = 30 # Only hold the trade for twenty minutes\n",
        "\n",
        "    after_td = td.loc[idx:idx+max_holdtime+1]\n",
        "\n",
        "    basis = td['close'].loc[idx]\n",
        "    max_price = basis   # Initially the max price is the basis - No Shorting to Start\n",
        "    min_price = basis - (basis*pct)\n",
        "    time_stop = idx + max_holdtime\n",
        "    time_counter = idx\n",
        "\n",
        "    #print(f\"Basis: {basis}\")\n",
        "\n",
        "    for i, row in after_td.iterrows():\n",
        "        close = row['close']\n",
        "        #print(f\"Close: {close}, Max: {max_price}, Min: {min_price}, Counter: {time_counter-idx}\")\n",
        "        if close > max_price:\n",
        "            max_price = close\n",
        "            min_price = max_price - (max_price * pct)\n",
        "        elif close < min_price:\n",
        "            profit = (close - basis) / basis\n",
        "            return [i, profit]\n",
        "\n",
        "        time_counter += 1\n",
        "        if time_counter > time_stop:\n",
        "            break\n",
        "\n",
        "    # If the loop ends without triggering stop loss, calculate the profit based on the last close\n",
        "    profit = (close - basis) / basis\n",
        "    return profit\n",
        "\n",
        "\n",
        "df = pd.read_excel('2022_m1to3_appl.xlsx')\n",
        "# Sort the Data from oldest to newest\n",
        "df = df.sort_values(by='Datetime').reset_index(drop=True)\n",
        "\n",
        "# List of Testing Variables\n",
        "Data_order = [\"Random\",\"Sorted\"] # *combination[3]\n",
        "#Underlying_data = [\"Percent Change\",\"Raw Data\"]\n",
        "Field_size = [10,20,50,100,200,300] # *combination[2]\n",
        "Derivatives = [[],[\"dydx\"],[\"dydx\",\"dydx2\"]] # *combination[0]\n",
        "TAs = [[],[\"EMA\"],[\"EMA\",\"SMA\"]] # *combination[1]\n",
        "\n",
        "all_combinations = itertools.product(Derivatives, TAs, Field_size, Data_order)\n",
        "\n",
        "# Getting all of the trading days because trades can only occur during trading day\n",
        "df['Time'] = df['Datetime'].dt.time\n",
        "start_time = pd.to_datetime('09:00:00').time()\n",
        "end_time = pd.to_datetime('16:00:00').time()\n",
        "TradingDay_df = df[(df['Time'] > start_time) & (df['Time'] < end_time) & (df.index >= 201)]\n",
        "\n",
        "df['Profit'] = TradingDay_df.apply(trail_stoploss, axis=1, tradingdata=df,whole_percentage=5)\n",
        "\n",
        "#applying EMAs SMAs\n",
        "EMAs = [8,10,20,50,75,100]\n",
        "SMAs = [8,10,20,50,75,100]\n",
        "\n",
        "\n",
        "for EMA in EMAs:\n",
        "    df[f'EMA{EMA}'] = ta.ema(df['close'], length=EMA)\n",
        "    df[f'EMA{EMA}_pct'] = df[f'EMA{EMA}'].pct_change()\n",
        "    df = df.drop([f'EMA{EMA}'],axis=1).copy()\n",
        "\n",
        "for SMA in SMAs:\n",
        "    df[f'SMA{SMA}'] = ta.sma(df['close'], length=SMA)\n",
        "    df[f'SMA{SMA}_pct'] = df[f'SMA{SMA}'].pct_change()\n",
        "    df = df.drop([f'SMA{SMA}'],axis=1).copy()\n",
        "\n",
        "# 1st (pct chg)\n",
        "df['dydx'] = df['close'].pct_change()\n",
        "\n",
        "# 2nd\n",
        "df['dydx2'] = df['dydx'].pct_change()\n",
        "\n",
        "df = df.drop(['Datetime','open','high','low','close','volume','Stock','interval','Time'], axis=1)\n",
        "print(df.info())\n",
        "\n",
        "df1 = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PisihBVy2uSK",
        "outputId": "4e5e3f3b-f7e8-4de2-9d98-6ed8f87716ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 25039 entries, 237 to 50662\n",
            "Data columns (total 15 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Profit      25039 non-null  float64\n",
            " 1   EMA8_pct    25039 non-null  float64\n",
            " 2   EMA10_pct   25039 non-null  float64\n",
            " 3   EMA20_pct   25039 non-null  float64\n",
            " 4   EMA50_pct   25039 non-null  float64\n",
            " 5   EMA75_pct   25039 non-null  float64\n",
            " 6   EMA100_pct  25039 non-null  float64\n",
            " 7   SMA8_pct    25039 non-null  float64\n",
            " 8   SMA10_pct   25039 non-null  float64\n",
            " 9   SMA20_pct   25039 non-null  float64\n",
            " 10  SMA50_pct   25039 non-null  float64\n",
            " 11  SMA75_pct   25039 non-null  float64\n",
            " 12  SMA100_pct  25039 non-null  float64\n",
            " 13  dydx        25039 non-null  float64\n",
            " 14  dydx2       25039 non-null  float64\n",
            "dtypes: float64(15)\n",
            "memory usage: 3.1 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#df = df.drop(['Datetime','open','high','low','close','volume','Stock','interval','Time'], axis=1)\n",
        "import numpy as np\n",
        "\n",
        "df = df1.copy()\n",
        "\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df = df.dropna()\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# Select the columns you want to normalize (all except 'Profit' if it's the target)\n",
        "columns_to_scale = df.columns.drop(['Profit'])\n",
        "\n",
        "# Fit the scaler on the selected columns and transform the data\n",
        "df[columns_to_scale] = min_max_scaler.fit_transform(df[columns_to_scale])\n",
        "\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df = df.dropna()\n",
        "print(df.info())\n",
        "\n",
        "\n",
        "\n",
        "with pd.ExcelWriter('output.xlsx',engine='xlsxwriter') as writer:\n",
        "    df.to_excel(writer, sheet_name=\"Sheet1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrqncny6sOpy"
      },
      "source": [
        "# Pytrorch CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IEF6QeesOpz"
      },
      "source": [
        "### 1. Prepare Your Data\n",
        "- In order to make the data in the correct format, you first need to packet the data\n",
        "  - This is not the same as previous attempts as the data is not flattened, but instead keeps its shape for the CNN\n",
        "  - The end result is a LoLoL which is a list of lists of lists [List of arrays consisting of lists], where the arrays are the packets, and the lists inside the arrays are the rows\n",
        "\n",
        "- Expected output:\n",
        "\n",
        "      array([[[A, B],\n",
        "              [1, 2],\n",
        "              [3, 3]],\n",
        "             [[C, D],\n",
        "              [3, 3],\n",
        "              [4, 4]],\n",
        "\n",
        "\n",
        "- Steps:\n",
        "  1. Packet the data\n",
        "  2. Turn it into a np array\n",
        "  3. Turn it into a tensor\n",
        "  4. Unsqueeze the tensor (format it for CNNs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEAvC_wSsOpz",
        "outputId": "de755fc5-3128-4045-f311-4cfbb0abb9d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([25020, 1, 3, 15])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rybot\\AppData\\Local\\Temp\\ipykernel_17340\\844899893.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  packets_tensor = torch.tensor(Packets).float()\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Packet the data\n",
        "Packets = []\n",
        "packet_size = 20\n",
        "\n",
        "for i in range(packet_size, len(df)+1):\n",
        "    snapshot = df.iloc[i-3:i].values\n",
        "    Packets.append(snapshot)\n",
        "\n",
        "# Convert to tensor and reshape\n",
        "packets_tensor = torch.tensor(Packets).float()\n",
        "packets_tensor = packets_tensor.unsqueeze(1)\n",
        "print(packets_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lenet CNN Model\n",
        "https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([25020, 1, 3, 15])\n",
            "Packets tensor shape: torch.Size([25020, 1, 3, 15])\n",
            "Target tensor shape: torch.Size([25020])\n",
            "[INFO] training the network...\n",
            "[INFO] EPOCH: 1/10\n",
            "Train loss: 0.000179, Val loss: 0.000018\n",
            "\n",
            "[INFO] EPOCH: 2/10\n",
            "Train loss: 0.000014, Val loss: 0.000011\n",
            "\n",
            "[INFO] EPOCH: 3/10\n",
            "Train loss: 0.000011, Val loss: 0.000010\n",
            "\n",
            "[INFO] EPOCH: 4/10\n",
            "Train loss: 0.000011, Val loss: 0.000010\n",
            "\n",
            "[INFO] EPOCH: 5/10\n",
            "Train loss: 0.000010, Val loss: 0.000010\n",
            "\n",
            "[INFO] EPOCH: 6/10\n",
            "Train loss: 0.000010, Val loss: 0.000010\n",
            "\n",
            "[INFO] EPOCH: 7/10\n",
            "Train loss: 0.000010, Val loss: 0.000009\n",
            "\n",
            "[INFO] EPOCH: 8/10\n",
            "Train loss: 0.000010, Val loss: 0.000009\n",
            "\n",
            "[INFO] EPOCH: 9/10\n",
            "Train loss: 0.000010, Val loss: 0.000009\n",
            "\n",
            "[INFO] EPOCH: 10/10\n",
            "Train loss: 0.000010, Val loss: 0.000009\n",
            "\n",
            "[INFO] Total training time: 38.95 seconds\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU, MSELoss\n",
        "from torch import flatten\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Packet the data\n",
        "Packets = []\n",
        "packet_size = 20\n",
        "\n",
        "for i in range(packet_size, len(df)+1):\n",
        "    snapshot = df.iloc[i-3:i].values\n",
        "    Packets.append(snapshot)\n",
        "\n",
        "# Convert to tensor and reshape\n",
        "packets_tensor = torch.tensor(Packets).float()\n",
        "packets_tensor = packets_tensor.unsqueeze(1)\n",
        "print(packets_tensor.shape)\n",
        "\n",
        "# Define the CNN Model\n",
        "class LeNetTabular(Module):\n",
        "    def __init__(self, numChannels):\n",
        "        super(LeNetTabular, self).__init__()\n",
        "        # First CONV => RELU => POOL layer\n",
        "        self.conv1 = Conv2d(in_channels=numChannels, out_channels=16, kernel_size=(1, 2))\n",
        "        self.relu1 = ReLU()\n",
        "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n",
        "        # Second CONV => RELU => POOL layer\n",
        "        self.conv2 = Conv2d(in_channels=16, out_channels=32, kernel_size=(1, 2))\n",
        "        self.relu2 = ReLU()\n",
        "        self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n",
        "        # Fully connected layers\n",
        "        self.fc1 = Linear(in_features=32 * 1 * 11, out_features=50)\n",
        "        self.relu3 = ReLU()\n",
        "        self.fc2 = Linear(in_features=50, out_features=1)  # Predicting \"Profit\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "INIT_LR = 1e-4\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "TRAIN_SPLIT = 0.75\n",
        "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data Preparation\n",
        "# Assume df is your dataframe with 25517 rows\n",
        "# You already have `packets_tensor` (shape: [25517, 1, 3, 15]) created from df\n",
        "# The 'Profit' column is the target column\n",
        "target_tensor = torch.tensor(df['Profit'].values).float()\n",
        "target_tensor = target_tensor[:packets_tensor.shape[0]]\n",
        "\n",
        "\n",
        "print(\"Packets tensor shape:\", packets_tensor.shape)\n",
        "print(\"Target tensor shape:\", target_tensor.shape)\n",
        "\n",
        "\n",
        "# Create the TensorDataset and split into training/validation\n",
        "dataset = TensorDataset(packets_tensor, target_tensor)\n",
        "numTrainSamples = int(len(dataset) * TRAIN_SPLIT)\n",
        "numValSamples = len(dataset) - numTrainSamples\n",
        "trainData, valData = random_split(dataset, [numTrainSamples, numValSamples])\n",
        "\n",
        "# DataLoaders for training and validation\n",
        "trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=BATCH_SIZE)\n",
        "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LeNetTabular(numChannels=1).to(device)\n",
        "opt = Adam(model.parameters(), lr=INIT_LR)\n",
        "lossFn = MSELoss()\n",
        "\n",
        "# Training Loop\n",
        "H = {\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": []\n",
        "}\n",
        "\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "    model.train()\n",
        "    totalTrainLoss = 0\n",
        "    totalValLoss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for (x, y) in trainDataLoader:\n",
        "        (x, y) = (x.to(device), y.to(device))\n",
        "\n",
        "        # Perform forward pass, compute loss, backward pass, and update weights\n",
        "        pred = model(x)\n",
        "        loss = lossFn(pred.squeeze(), y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # Add the training loss\n",
        "        totalTrainLoss += loss.item()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (x, y) in valDataLoader:\n",
        "            (x, y) = (x.to(device), y.to(device))\n",
        "            pred = model(x)\n",
        "            valLoss = lossFn(pred.squeeze(), y)\n",
        "            totalValLoss += valLoss.item()\n",
        "\n",
        "    # Calculate the average losses for the epoch\n",
        "    avgTrainLoss = totalTrainLoss / len(trainDataLoader)\n",
        "    avgValLoss = totalValLoss / len(valDataLoader)\n",
        "\n",
        "    # Save losses for plotting later\n",
        "    H[\"train_loss\"].append(avgTrainLoss)\n",
        "    H[\"val_loss\"].append(avgValLoss)\n",
        "\n",
        "    # Print epoch info\n",
        "    print(f\"[INFO] EPOCH: {e+1}/{EPOCHS}\")\n",
        "    print(f\"Train loss: {avgTrainLoss:.6f}, Val loss: {avgValLoss:.6f}\\n\")\n",
        "\n",
        "# Final time\n",
        "endTime = time.time()\n",
        "print(f\"[INFO] Total training time: {endTime - startTime:.2f} seconds\")\n",
        "\n",
        "# Plotting the training/validation loss curves\n",
        "#plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training/Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.171401857864483e-05\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.24077995728576e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 9.243907880095414e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 9.64593703531359e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 8.855921972711685e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 8.582360096068219e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 9.916658279266534e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.975844962503529e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 9.86834022940605e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 9.43854536217259e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 8.926264949506583e-06\n",
            "Testing combination: lr=1e-05, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 8.470904535387286e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.2444051537608992e-05\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 1.4548156945684054e-05\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 9.762999116920044e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 9.881547199182358e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.146741341951104e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 9.336445572796724e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.0198118987467082e-05\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.370268738779004e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 8.982445715631986e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 9.546534231828576e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.702683191604517e-06\n",
            "Testing combination: lr=1e-05, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 9.619607922382895e-06\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.5428842075658506e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.710390073376737e-06\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 1.0182540104231484e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 1.112644885120526e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 1.0570109169544148e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 9.023638234125707e-06\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.1631260330970542e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 1.15493526302126e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 9.67648636607028e-06\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 1.5505559865548038e-05\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.958715137906198e-06\n",
            "Testing combination: lr=1e-05, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 9.128136131336333e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.1653118791372787e-05\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 7.944673427573434e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 7.980480695690004e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 1.525629700989491e-05\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 6.998604746689923e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 6.725196124543985e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 9.154382496490143e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 8.151370149316419e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 8.993342364693509e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 1.3291073001914347e-05\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 7.615362744904908e-06\n",
            "Testing combination: lr=0.0001, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 7.336956054949004e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 9.633027307894995e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.04571731311711e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 9.00361782423344e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 9.927045307356784e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.737084796217125e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 7.956161680897135e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 8.48653554867826e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 8.713013413602758e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 6.595626137006585e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 1.0314525692295746e-05\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 7.563074764592023e-06\n",
            "Testing combination: lr=0.0001, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 1.0355998019618635e-05\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.0283456801089972e-05\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 8.46997540882475e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 8.440243442348627e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 8.750421533922959e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 1.0803771249124928e-05\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 8.604733800299926e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 1.063800686542705e-05\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 1.0924691511662582e-05\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 8.54180967619367e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 9.858969081376148e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.56166151846279e-06\n",
            "Testing combination: lr=0.0001, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 8.783702961242239e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 8.889990652380443e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.628623956814408e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 6.945827946616859e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 1.012926647991681e-05\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 6.384904930209999e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 8.88797089434162e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 7.578563242430168e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 7.005861338099322e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 7.368094173318464e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 6.785276378204984e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 6.869991622983323e-06\n",
            "Testing combination: lr=0.001, batch_size=32, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 6.632440497654972e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 8.978752058116084e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 1.141849616125947e-05\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 6.572986138758561e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 6.820549953902498e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.30960789223811e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 1.1780574113243124e-05\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 8.358222880722642e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 8.61610415921284e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 6.215372701374189e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 8.441702568828133e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 8.188559836618915e-06\n",
            "Testing combination: lr=0.001, batch_size=64, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 6.601499899725426e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 8.932326321029199e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 9.45898613726782e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=16, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 6.19061288674931e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 6.7608079545458835e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 9.30744299322975e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=16, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 6.7294428882465874e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=10\n",
            "Avg Val Loss: 9.337549040445046e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=20\n",
            "Avg Val Loss: 8.941721753959724e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=32, conv2_out_channels=32, epcoch=30\n",
            "Avg Val Loss: 8.739011960011451e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=10\n",
            "Avg Val Loss: 8.680771733619326e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=20\n",
            "Avg Val Loss: 8.62730649361988e-06\n",
            "Testing combination: lr=0.001, batch_size=128, conv1_out_channels=32, conv2_out_channels=64, epcoch=30\n",
            "Avg Val Loss: 6.454237819172927e-06\n",
            "Best parameters: (0.001, 128, 16, 32, 30) with validation loss 0.0000\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import torch\n",
        "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU, MSELoss\n",
        "from torch import flatten\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'lr': [1e-5, 1e-4, 1e-3],  # Learning rates to test\n",
        "    'batch_size': [32, 64, 128],  # Batch sizes to test\n",
        "    'conv1_out_channels': [16, 32],  # Number of filters in the first conv layer\n",
        "    'conv2_out_channels': [32, 64],  # Number of filters in the second conv layer\n",
        "    'epcoch':[10,20,30]\n",
        "}\n",
        "\n",
        "# Generate all combinations of hyperparameters\n",
        "param_combinations = list(itertools.product(param_grid['lr'], \n",
        "                                            param_grid['batch_size'], \n",
        "                                            param_grid['conv1_out_channels'], \n",
        "                                            param_grid['conv2_out_channels'],\n",
        "                                            param_grid['epcoch']))\n",
        "\n",
        "# Iterate through each combination\n",
        "best_val_loss = float('inf')\n",
        "best_params = None\n",
        "\n",
        "TRAIN_SPLIT = 0.75\n",
        "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for params in param_combinations:\n",
        "    lr, batch_size, conv1_out_channels, conv2_out_channels, epcoch = params\n",
        "    EPOCHS = epcoch\n",
        "    print(f\"Testing combination: lr={lr}, batch_size={batch_size}, conv1_out_channels={conv1_out_channels}, conv2_out_channels={conv2_out_channels}, epcoch={epcoch}\")\n",
        "    \n",
        "    # Rebuild your model with the new hyperparameters\n",
        "    class LeNetTabular(Module):\n",
        "        def __init__(self, numChannels):\n",
        "            super(LeNetTabular, self).__init__()\n",
        "            self.conv1 = Conv2d(in_channels=numChannels, out_channels=conv1_out_channels, kernel_size=(1, 2))\n",
        "            self.relu1 = ReLU()\n",
        "            self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n",
        "            self.conv2 = Conv2d(in_channels=conv1_out_channels, out_channels=conv2_out_channels, kernel_size=(1, 2))\n",
        "            self.relu2 = ReLU()\n",
        "            self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n",
        "            self.fc1 = Linear(in_features=conv2_out_channels * 1 * 11, out_features=50)\n",
        "            self.relu3 = ReLU()\n",
        "            self.fc2 = Linear(in_features=50, out_features=1)  # Predicting \"Profit\"\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.maxpool1(x)\n",
        "            x = self.conv2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.maxpool2(x)\n",
        "            x = flatten(x, 1)\n",
        "            x = self.fc1(x)\n",
        "            x = self.relu3(x)\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    # Initialize the model, loss function, optimizer\n",
        "    model = LeNetTabular(numChannels=1).to(device)\n",
        "    opt = Adam(model.parameters(), lr=lr)\n",
        "    lossFn = MSELoss()\n",
        "\n",
        "    # Packet the data\n",
        "    Packets = []\n",
        "    packet_size = 20\n",
        "\n",
        "    for i in range(packet_size, len(df)+1):\n",
        "        snapshot = df.iloc[i-3:i].values\n",
        "        Packets.append(snapshot)\n",
        "\n",
        "    # Convert to tensor and reshape\n",
        "    packets_tensor = torch.tensor(Packets).float()\n",
        "    packets_tensor = packets_tensor.unsqueeze(1)\n",
        "\n",
        "    target_tensor = torch.tensor(df['Profit'].values).float()\n",
        "    target_tensor = target_tensor[:packets_tensor.shape[0]]\n",
        "\n",
        "    # Create the TensorDataset and split into training/validation\n",
        "    dataset = TensorDataset(packets_tensor, target_tensor)\n",
        "    numTrainSamples = int(len(dataset) * TRAIN_SPLIT)\n",
        "    numValSamples = len(dataset) - numTrainSamples\n",
        "    trainData, valData = random_split(dataset, [numTrainSamples, numValSamples])\n",
        "\n",
        "    # Re-create DataLoaders with the new batch size\n",
        "    trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=batch_size)\n",
        "    valDataLoader = DataLoader(valData, batch_size=batch_size)\n",
        "\n",
        "    # Training Loop (simplified)\n",
        "    for e in range(EPOCHS):\n",
        "        model.train()\n",
        "        totalTrainLoss = 0\n",
        "        totalValLoss = 0\n",
        "\n",
        "        # Training loop\n",
        "        for (x, y) in trainDataLoader:\n",
        "            (x, y) = (x.to(device), y.to(device))\n",
        "            pred = model(x)\n",
        "            loss = lossFn(pred.squeeze(), y)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            totalTrainLoss += loss.item()\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for (x, y) in valDataLoader:\n",
        "                (x, y) = (x.to(device), y.to(device))\n",
        "                pred = model(x)\n",
        "                valLoss = lossFn(pred.squeeze(), y)\n",
        "                totalValLoss += valLoss.item()\n",
        "\n",
        "        # Calculate the average losses for the epoch\n",
        "        avgValLoss = totalValLoss / len(valDataLoader)\n",
        "\n",
        "    # Check if current parameters result in a lower validation loss\n",
        "    print(\"Avg Val Loss:\", avgValLoss)\n",
        "    if avgValLoss < best_val_loss:\n",
        "        best_val_loss = avgValLoss\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Best parameters: {best_params} with validation loss {best_val_loss:.4f}\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN with the best Grid Search Parameters on all 2022 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import torch\n",
        "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU, MSELoss\n",
        "from torch import flatten\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'lr': [1e-3],  # Learning rates to test\n",
        "    'batch_size': [128],  # Batch sizes to test\n",
        "    'conv1_out_channels': [16],  # Number of filters in the first conv layer\n",
        "    'conv2_out_channels': [32],  # Number of filters in the second conv layer\n",
        "    'epcoch':[30]\n",
        "}\n",
        "\n",
        "# Generate all combinations of hyperparameters\n",
        "param_combinations = list(itertools.product(param_grid['lr'], \n",
        "                                            param_grid['batch_size'], \n",
        "                                            param_grid['conv1_out_channels'], \n",
        "                                            param_grid['conv2_out_channels'],\n",
        "                                            param_grid['epcoch']))\n",
        "\n",
        "# Iterate through each combination\n",
        "best_val_loss = float('inf')\n",
        "best_params = None\n",
        "\n",
        "TRAIN_SPLIT = 0.75\n",
        "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for params in param_combinations:\n",
        "    lr, batch_size, conv1_out_channels, conv2_out_channels, epcoch = params\n",
        "    EPOCHS = epcoch\n",
        "    print(f\"Testing combination: lr={lr}, batch_size={batch_size}, conv1_out_channels={conv1_out_channels}, conv2_out_channels={conv2_out_channels}, epcoch={epcoch}\")\n",
        "    \n",
        "    # Rebuild your model with the new hyperparameters\n",
        "    class LeNetTabular(Module):\n",
        "        def __init__(self, numChannels):\n",
        "            super(LeNetTabular, self).__init__()\n",
        "            self.conv1 = Conv2d(in_channels=numChannels, out_channels=conv1_out_channels, kernel_size=(1, 2))\n",
        "            self.relu1 = ReLU()\n",
        "            self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n",
        "            self.conv2 = Conv2d(in_channels=conv1_out_channels, out_channels=conv2_out_channels, kernel_size=(1, 2))\n",
        "            self.relu2 = ReLU()\n",
        "            self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n",
        "            self.fc1 = Linear(in_features=conv2_out_channels * 1 * 11, out_features=50)\n",
        "            self.relu3 = ReLU()\n",
        "            self.fc2 = Linear(in_features=50, out_features=1)  # Predicting \"Profit\"\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.maxpool1(x)\n",
        "            x = self.conv2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.maxpool2(x)\n",
        "            x = flatten(x, 1)\n",
        "            x = self.fc1(x)\n",
        "            x = self.relu3(x)\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    # Initialize the model, loss function, optimizer\n",
        "    model = LeNetTabular(numChannels=1).to(device)\n",
        "    opt = Adam(model.parameters(), lr=lr)\n",
        "    lossFn = MSELoss()\n",
        "\n",
        "    # Packet the data\n",
        "    Packets = []\n",
        "    packet_size = 20\n",
        "\n",
        "    for i in range(packet_size, len(df)+1):\n",
        "        snapshot = df.iloc[i-3:i].values\n",
        "        Packets.append(snapshot)\n",
        "\n",
        "    # Convert to tensor and reshape\n",
        "    packets_tensor = torch.tensor(Packets).float()\n",
        "    packets_tensor = packets_tensor.unsqueeze(1)\n",
        "\n",
        "    target_tensor = torch.tensor(df['Profit'].values).float()\n",
        "    target_tensor = target_tensor[:packets_tensor.shape[0]]\n",
        "\n",
        "    # Create the TensorDataset and split into training/validation\n",
        "    dataset = TensorDataset(packets_tensor, target_tensor)\n",
        "    numTrainSamples = int(len(dataset) * TRAIN_SPLIT)\n",
        "    numValSamples = len(dataset) - numTrainSamples\n",
        "    trainData, valData = random_split(dataset, [numTrainSamples, numValSamples])\n",
        "\n",
        "    # Re-create DataLoaders with the new batch size\n",
        "    trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=batch_size)\n",
        "    valDataLoader = DataLoader(valData, batch_size=batch_size)\n",
        "\n",
        "    # Training Loop (simplified)\n",
        "    for e in range(EPOCHS):\n",
        "        model.train()\n",
        "        totalTrainLoss = 0\n",
        "        totalValLoss = 0\n",
        "\n",
        "        # Training loop\n",
        "        for (x, y) in trainDataLoader:\n",
        "            (x, y) = (x.to(device), y.to(device))\n",
        "            pred = model(x)\n",
        "            loss = lossFn(pred.squeeze(), y)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            totalTrainLoss += loss.item()\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for (x, y) in valDataLoader:\n",
        "                (x, y) = (x.to(device), y.to(device))\n",
        "                pred = model(x)\n",
        "                valLoss = lossFn(pred.squeeze(), y)\n",
        "                totalValLoss += valLoss.item()\n",
        "\n",
        "        # Calculate the average losses for the epoch\n",
        "        avgValLoss = totalValLoss / len(valDataLoader)\n",
        "\n",
        "    # Check if current parameters result in a lower validation loss\n",
        "    print(\"Avg Val Loss:\", avgValLoss)\n",
        "    if avgValLoss < best_val_loss:\n",
        "        best_val_loss = avgValLoss\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Best parameters: {best_params} with validation loss {best_val_loss:.4f}\") "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
